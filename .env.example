# .env.example

# ===================================================================
#  LLM Provider Configuration
# ===================================================================
# This file stores secrets and connection details for LLM providers.
# Copy this file to .env and fill in the required values.

# Required for Google Gemini. Your API key for the Google AI platform.
GOOGLE_API_KEY="your-google-api-key"

# Required for LM Studio. The base URL for your local LM Studio server.
LMSTUDIO_BASE_URL="http://localhost:1234/v1"

# Required for Ollama. The base URL for your local Ollama server.
OLLAMA_BASE_URL="http://localhost:11434"

# Overrides the default location for run reports.
# AGENTIC_SCAFFOLD_ARCHIVER_ENABLED=false
# AGENTIC_SCAFFOLD_ARCHIVE_PATH=/path/to/my/reports
