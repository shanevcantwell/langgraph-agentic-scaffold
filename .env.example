# .env.example

# ===================================================================
#  LLM Provider Configuration
# ===================================================================
# This file stores secrets and connection details for LLM providers.
# Copy this file to .env and fill in the required values.

# Required for Google Gemini. Your API key for the Google AI platform.
# Used by the 'gemini_pro' and 'gemini_flash' providers in config.yaml.
GOOGLE_API_KEY="your-google-api-key"

# Required for LM Studio. The base URL for your local LM Studio server.
# Used by the 'lmstudio_router' and 'lmstudio_specialist' providers in config.yaml.
LMSTUDIO_BASE_URL="http://localhost:1234/v1"
# LMSTUDIO_TIMEOUT=180

# Required for Ollama. The base URL for your local Ollama server.
# Used by the 'local_ollama' provider in config.yaml.
OLLAMA_BASE_URL="http://localhost:11434"

# Overrides the default location for run reports.
# AGENTIC_SCAFFOLD_ARCHIVER_ENABLED=false
# AGENTIC_SCAFFOLD_ARCHIVE_PATH=/path/to/my/reports
